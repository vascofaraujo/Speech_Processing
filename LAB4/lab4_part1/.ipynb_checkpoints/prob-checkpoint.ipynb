{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5efcb739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vasco/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline, flatten\n",
    "from nltk.lm import MLE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7fb88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_txt = 'utf8_s1.txt'\n",
    "\n",
    "with open(new_file_txt, 'r') as file:\n",
    "    data = file.read().replace('<s>', '').replace('</s>','').replace('\\n', '')\n",
    "    \n",
    "bigrams = list(nltk.ngrams(data.split(), n=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38d89309",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(data)\n",
    "words = nltk.word_tokenize(data)\n",
    "\n",
    "bigramList = []\n",
    "\n",
    "for sentence in sents:\n",
    "    sequence = word_tokenize(sentence)\n",
    "    bigramList.extend(list(nltk.ngrams(sequence,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b7861ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, bigramList)\n",
    "\n",
    "model = MLE(n) \n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "644ed951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 2 ngram orders and 2879093 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(model.counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ed22d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ele', 'sofreu', 'uma', 'queda', 'no', 'primeiro', 'jogo', '.']\n"
     ]
    }
   ],
   "source": [
    "inputSentence = \"s2.txt\"\n",
    "with open(inputSentence, 'r') as file:\n",
    "    data = file.read().replace('<s>', '').replace('</s>','').replace('\\n', '')\n",
    "\n",
    "words = nltk.word_tokenize(data)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93b2429a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.227916130655749e-18\n"
     ]
    }
   ],
   "source": [
    "final_prob = model.score(words[0])\n",
    "for i in range(1,len(words)):\n",
    "    final_prob = final_prob*model.score(words[i], words[i-1].split())\n",
    "print(final_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b9128bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileOut = \"prob_\" + inputSentence\n",
    "\n",
    "f = open(fileOut, \"w\")\n",
    "f.write(\"Probability of {} in {}: {}\".format(data, inputSentence, final_prob))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70347f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'jogador', 'sofreu', 'uma', 'queda', 'no', 'primeiro', 'jogo', '.']\n"
     ]
    }
   ],
   "source": [
    "inputSentence = \"s3.txt\"\n",
    "with open(inputSentence, 'r') as file:\n",
    "    data = file.read().replace('<s>', '').replace('</s>','').replace('\\n', '')\n",
    "\n",
    "words = nltk.word_tokenize(data)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ed55877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "final_prob = model.score(words[0])\n",
    "for i in range(1,len(words)):\n",
    "    final_prob = final_prob*model.score(words[i], words[i-1].split())\n",
    "print(final_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1fa934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileOut = \"prob_\" + inputSentence\n",
    "\n",
    "f = open(fileOut, \"w\")\n",
    "f.write(\"Probability of {} in {}: {}\".format(data, inputSentence, final_prob))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
